{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctr(f):\n",
    "    name = str(f).split('/')[-1].split('.')[0]\n",
    "    t = tensor(ldict[name])\n",
    "    return t.reshape(30,2).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "def linear_expectation(probs, values):\n",
    "    assert(len(values) == probs.ndimension() - 2)\n",
    "    expectation = []\n",
    "    for i in range(2, probs.ndimension()):\n",
    "        # Marginalise probabilities\n",
    "        marg = probs\n",
    "        for j in range(probs.ndimension() - 1, 1, -1):\n",
    "            if i != j:\n",
    "                marg = marg.sum(j, keepdim=False)\n",
    "        # Calculate expectation along axis `i`\n",
    "        expectation.append((marg * values[len(expectation)]).sum(-1, keepdim=False))\n",
    "    return torch.stack(expectation, -1)\n",
    "\n",
    "\n",
    "def normalized_linspace(length, dtype=None, device=None):\n",
    "    \"\"\"Generate a vector with values ranging from -1 to 1.\n",
    "    Note that the values correspond to the \"centre\" of each cell, so\n",
    "    -1 and 1 are always conceptually outside the bounds of the vector.\n",
    "    For example, if length = 4, the following vector is generated:\n",
    "    ```text\n",
    "     [ -0.75, -0.25,  0.25,  0.75 ]\n",
    "     ^              ^             ^\n",
    "    -1              0             1\n",
    "    ```\n",
    "    Args:\n",
    "        length: The length of the vector\n",
    "    Returns:\n",
    "        The generated vector\n",
    "    \"\"\"\n",
    "    first = -(length - 1) / length\n",
    "    last = (length - 1) / length\n",
    "    return torch.linspace(first, last, length, dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "def soft_argmax(heatmaps, normalized_coordinates=True):\n",
    "    if normalized_coordinates:\n",
    "        values = [normalized_linspace(d, dtype=heatmaps.dtype, device=heatmaps.device)\n",
    "                  for d in heatmaps.size()[2:]]\n",
    "    else:\n",
    "        values = [torch.arange(0, d, dtype=heatmaps.dtype, device=heatmaps.device)\n",
    "                  for d in heatmaps.size()[2:]]\n",
    "    return linear_expectation(heatmaps, values).flip(-1)\n",
    "\n",
    "\n",
    "def dsnt(heatmaps, **kwargs):\n",
    "    \"\"\"Differentiable spatial to numerical transform.\n",
    "    Args:\n",
    "        heatmaps (torch.Tensor): Spatial representation of locations\n",
    "    Returns:\n",
    "        Numerical coordinates corresponding to the locations in the heatmaps.\n",
    "    \"\"\"\n",
    "    return soft_argmax(heatmaps, **kwargs)\n",
    "\n",
    "\n",
    "def flat_softmax(inp):\n",
    "    \"\"\"Compute the softmax with all but the first two tensor dimensions combined.\"\"\"\n",
    "\n",
    "    orig_size = inp.size()\n",
    "    flat = inp.view(-1, reduce(mul, orig_size[2:]))\n",
    "    flat = torch.nn.functional.softmax(flat, -1)\n",
    "    return flat.view(*orig_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_losses(actual, target):\n",
    "    \"\"\"Calculate the average Euclidean loss for multi-point samples.\n",
    "    Each sample must contain `n` points, each with `d` dimensions. For example,\n",
    "    in the MPII human pose estimation task n=16 (16 joint locations) and\n",
    "    d=2 (locations are 2D).\n",
    "    Args:\n",
    "        actual (Tensor): Predictions (B x L x D)\n",
    "        target (Tensor): Ground truth target (B x L x D)\n",
    "    \"\"\"\n",
    "\n",
    "    assert actual.size() == target.size(), 'input tensors must have the same size'\n",
    "\n",
    "    # Calculate Euclidean distances between actual and target locations\n",
    "    diff = actual - target\n",
    "    dist_sq = diff.pow(2).sum(-1, keepdim=False)\n",
    "    dist = dist_sq.sqrt()\n",
    "    return dist\n",
    "\n",
    "def make_gauss(means, size, sigma, normalize=True):\n",
    "    \"\"\"Draw Gaussians.\n",
    "    This function is differential with respect to means.\n",
    "    Note on ordering: `size` expects [..., depth, height, width], whereas\n",
    "    `means` expects x, y, z, ...\n",
    "    Args:\n",
    "        means: coordinates containing the Gaussian means (units: normalized coordinates)\n",
    "        size: size of the generated images (units: pixels)\n",
    "        sigma: standard deviation of the Gaussian (units: pixels)\n",
    "        normalize: when set to True, the returned Gaussians will be normalized\n",
    "    \"\"\"\n",
    "\n",
    "    dim_range = range(-1, -(len(size) + 1), -1)\n",
    "    coords_list = [normalized_linspace(s, dtype=means.dtype, device=means.device)\n",
    "                   for s in reversed(size)]\n",
    "\n",
    "    # PDF = exp(-(x - \\mu)^2 / (2 \\sigma^2))\n",
    "\n",
    "    # dists <- (x - \\mu)^2\n",
    "    dists = [(x - mean) ** 2 for x, mean in zip(coords_list, means.split(1, -1))]\n",
    "\n",
    "    # ks <- -1 / (2 \\sigma^2)\n",
    "    stddevs = [2 * sigma / s for s in reversed(size)]\n",
    "    ks = [-0.5 * (1 / stddev) ** 2 for stddev in stddevs]\n",
    "\n",
    "    exps = [(dist * k).exp() for k, dist in zip(ks, dists)]\n",
    "\n",
    "    # Combine dimensions of the Gaussian\n",
    "    gauss = reduce(mul, [\n",
    "        reduce(lambda t, d: t.unsqueeze(d), filter(lambda d: d != dim, dim_range), dist)\n",
    "        for dim, dist in zip(dim_range, exps)\n",
    "    ])\n",
    "\n",
    "    if not normalize:\n",
    "        return gauss\n",
    "\n",
    "    # Normalize the Gaussians\n",
    "    val_sum = reduce(lambda t, dim: t.sum(dim, keepdim=True), dim_range, gauss) + 1e-24\n",
    "    return gauss / val_sum\n",
    "\n",
    "def _divergence_reg_losses(heatmaps, mu_t, sigma_t, divergence):\n",
    "    ndims = mu_t.size(-1)\n",
    "    assert heatmaps.dim() == ndims + 2, 'expected heatmaps to be a {}D tensor'.format(ndims + 2)\n",
    "    assert heatmaps.size()[:-ndims] == mu_t.size()[:-1]\n",
    "\n",
    "    gauss = make_gauss(mu_t, heatmaps.size()[2:], sigma_t)\n",
    "    divergences = divergence(heatmaps, gauss, ndims)\n",
    "    return divergences\n",
    "\n",
    "def _kl(p, q, ndims):\n",
    "    eps = 1e-24\n",
    "    unsummed_kl = p * ((p + eps).log() - (q + eps).log())\n",
    "    kl_values = reduce(lambda t, _: t.sum(-1, keepdim=False), range(ndims), unsummed_kl)\n",
    "    return kl_values\n",
    "\n",
    "def _js(p, q, ndims):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * _kl(p, m, ndims) + 0.5 * _kl(q, m, ndims)\n",
    "\n",
    "def js_reg_losses(heatmaps, mu_t, sigma_t):\n",
    "    \"\"\"Calculate Jensen-Shannon divergences between heatmaps and target Gaussians.\n",
    "    Args:\n",
    "        heatmaps (torch.Tensor): Heatmaps generated by the model\n",
    "        mu_t (torch.Tensor): Centers of the target Gaussians (in normalized units)\n",
    "        sigma_t (float): Standard deviation of the target Gaussians (in pixels)\n",
    "    Returns:\n",
    "        Per-location JS divergences.\n",
    "    \"\"\"\n",
    "\n",
    "    return _divergence_reg_losses(heatmaps, mu_t, sigma_t, _js)\n",
    "\n",
    "def average_loss(losses, mask=None):\n",
    "    \"\"\"Calculate the average of per-location losses.\n",
    "    Args:\n",
    "        losses (Tensor): Predictions (B x L)\n",
    "        mask (Tensor, optional): Mask of points to include in the loss calculation\n",
    "            (B x L), defaults to including everything\n",
    "    \"\"\"\n",
    "\n",
    "    if mask is not None:\n",
    "        assert mask.size() == losses.size(), 'mask must be the same size as losses'\n",
    "        losses = losses * mask\n",
    "        denom = mask.sum()\n",
    "    else:\n",
    "        denom = losses.numel()\n",
    "\n",
    "    # Prevent division by zero\n",
    "    if isinstance(denom, int):\n",
    "        denom = max(denom, 1)\n",
    "    else:\n",
    "        denom = denom.clamp(1)\n",
    "\n",
    "    return losses.sum() / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordRegressionNetwork(nn.Module):\n",
    "    def __init__(self, n_locations):\n",
    "        super().__init__()\n",
    "        m = resnet34()\n",
    "        m = nn.Sequential(*list(m.children())[:-2])\n",
    "        self.unet = DynamicUnet(m, 128, (128,128), norm_type=None)\n",
    "        self.hm_conv = nn.Conv2d(128, n_locations, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, images):\n",
    "        # 1. Run the images through our FCN\n",
    "        fcn_out = self.unet(images)\n",
    "        # 2. Use a 1x1 conv to get one unnormalized heatmap per location\n",
    "        unnormalized_heatmaps = self.hm_conv(fcn_out)\n",
    "        # 3. Normalize the heatmaps\n",
    "        heatmaps = flat_softmax(unnormalized_heatmaps)\n",
    "        # 4. Calculate the coordinates\n",
    "        coords = dsnt(heatmaps)\n",
    "\n",
    "        return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, preds, targs):\n",
    "        # 先将标签（都是-1到1之间）改为像素点的值\n",
    "        target_landmarks = targs * 112 + 112\n",
    "        # 根据坐标得到热力图\n",
    "        heatmaps = gen_label_heatmap(224, target_landmarks.int().float(), 1)\n",
    "        # 直接用MSE计算损失\n",
    "        loss_net = nn.MSELoss(reduction='sum')(preds, heatmaps)\n",
    "#         print(loss_net)\n",
    "        return loss_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scn = CoordRegressionNetwork(n_locations=30)\n",
    "hotmap = My_loss()\n",
    "learn = load_learner('export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
